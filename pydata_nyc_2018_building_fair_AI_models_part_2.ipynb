{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Building Fair AI Models\n",
    "\n",
    "## Presenter: Moninder Singh, IBM Research AI\n",
    "\n",
    "## PyData New York, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Summary](#summary)<br>\n",
    "[2. Data Used](#data_used)<br>\n",
    "[3. Learning model from Adult dataset to predict income](#2015-data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.1. Load data & create splits for learning/validating/testing model](#2015-data-load)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.2. Learning model from original data](#original-2015-data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.1. Metrics for original data](#original-2015-metrics)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2. Learning Logistic Regression (LR) classifier from original data](#lr_orig)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2.1. Training LR model from original data](#lr-train)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2.2. Validating LR model from original data](#lr-validate)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2.3. Testing LR model from original data](#lr-test)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[3.3 Bias Mitigation using post-processing technique - Reject Option Classifier](#reweighing-2015)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.3.1. Estimate optimal parameters for the ROC method](#reweighing-2015-transform)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.3.2. Transforming/Evaluating model](#lr_transf)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.3.3.2. Transforming and Computing Predictions from Validation Set](#lr-rw-validate)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.3.3.3. Transforming and Computing Predictions from Test Set](#lr-rw-test)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook demonstrates how a variety of fairness metrics and bias mitigation algorithms can used to detect and reduce bias when learning classifiers.\n",
    "\n",
    "Additional information is available in the accompanying [presentation](https://github.com/monindersingh/pydata2018_fairAI_models_tutorial/blob/master/pydata_nyc_2018_building_fair_AI_models.pdf).\n",
    "\n",
    "An open source Python toolkit, [AI Fairness 360 (AIF360)](https://github.com/IBM/AIF360), is used for this demonstration. This toolkit provides additional [examples](https://github.com/IBM/AIF360/tree/master/examples) of bias detection/mitigation as well as [guidance](http://aif360.mybluemix.net/resources#guidance) figuring out what metrics and algorithms will be most apropriate for a given problem.\n",
    "\n",
    "Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "\n",
    "Bias mitigation is explored via reject option classification (post-processing technique).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"use_case\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_used\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult Dataset\n",
    "\n",
    "Source: [https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult).\n",
    "\n",
    "This dataset is used to predict whether income exceeds $50K/yr. \n",
    "\n",
    "Contains 48842 instances, mix of continuous and discrete. `adult.data` contains\n",
    "the first 32561 instances which comprise the original training set while\n",
    "`adult.test` contains an additional 16281 instances which comprise the original\n",
    "test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "\n",
    "#Datasets\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset\n",
    "\n",
    "\n",
    "\n",
    "#Fairness Metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "#Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Bias Mitigation Techniques\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "#Utils\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#LIME\n",
    "from aif360.datasets.lime_encoder import LimeEncoder\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2015-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learning models from Adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2015-data-load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load data & create splits for learning/validating/testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train, validate, and test\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "adult_orig = load_preproc_data_adult(['sex'])\n",
    "\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "\n",
    "\n",
    "adult_orig_train, adult_orig_validate, adult_orig_test = \\\n",
    "                                    adult_orig.split([0.7,0.85], shuffle=True)\n",
    "\n",
    "sens_attr = adult_orig_train.protected_attribute_names[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Adult dataset details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Validation Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7326, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Test Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7327, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      ">50K <=50K\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n",
      "Male Female\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(adult_orig_train.features.shape)\n",
    "display(Markdown(\"#### Validation Dataset shape\"))\n",
    "print(adult_orig_validate.features.shape)\n",
    "display(Markdown(\"#### Test Dataset shape\"))\n",
    "print(adult_orig_test.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(adult_orig_train.favorable_label, adult_orig_train.unfavorable_label)\n",
    "print(adult_orig_train.metadata['label_maps'][0][adult_orig_train.favorable_label],\\\n",
    "      adult_orig_train.metadata['label_maps'][0][adult_orig_train.unfavorable_label])\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(adult_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(adult_orig_train.privileged_protected_attributes, \n",
    "      adult_orig_train.unprivileged_protected_attributes)\n",
    "print(adult_orig_train.metadata['protected_attribute_maps'][0][adult_orig_train.privileged_protected_attributes[0][0]],\n",
    "      adult_orig_train.metadata['protected_attribute_maps'][0][adult_orig_train.unprivileged_protected_attributes[0][0]])\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(adult_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"original-2015-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Learning model from original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"original-2015-metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Metrics for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.190698\n",
      "Disparate impact (ratio of unprivileged favorable mean to privileged favorable mean) = 0.366580\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "sens_idx = adult_orig_train.protected_attribute_names.index(sens_attr)\n",
    "privileged_groups =  [{sens_attr:adult_orig_train.privileged_protected_attributes[sens_idx][0]}]\n",
    "unprivileged_groups = [{sens_attr:adult_orig_train.unprivileged_protected_attributes[sens_idx][0]}]\n",
    "metric_adult_orig_train = BinaryLabelDatasetMetric(adult_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % \\\n",
    "                                                  metric_adult_orig_train.mean_difference())\n",
    "print(\"Disparate impact (ratio of unprivileged favorable mean to privileged favorable mean) = %f\" % \\\n",
    "                                                  metric_adult_orig_train.disparate_impact())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr_orig\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Learning Logistic Regression (LR) classifier from original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr-train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.1. Training LR model from original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\aif360\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Train model on given dataset\n",
    "\n",
    "dataset = adult_orig_train  # data to train on\n",
    "\n",
    "scale = StandardScaler().fit(dataset.features)   # remember the scale\n",
    "\n",
    "model = LogisticRegression()       # model to learn\n",
    "\n",
    "X_train = scale.transform(dataset.features)      #apply the scale\n",
    "y_train = dataset.labels.ravel()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "        sample_weight=dataset.instance_weights)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "#save model\n",
    "adult_orig_lr = model\n",
    "adult_orig_lr_scale = scale\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(model.classes_ == adult_orig_train.favorable_label)[0][0]\n",
    "\n",
    "adult_orig_train_pred = adult_orig_train.copy(deepcopy=True)\n",
    "adult_orig_train_pred.labels = y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain scores for validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_orig_validate_pred = adult_orig_validate.copy(deepcopy=True)\n",
    "X_valid = adult_orig_lr_scale.transform(adult_orig_validate_pred.features)\n",
    "y_valid = adult_orig_validate_pred.labels\n",
    "adult_orig_validate_pred.scores = adult_orig_lr.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "adult_orig_test_pred = adult_orig_test.copy(deepcopy=True)\n",
    "X_test = adult_orig_lr_scale.transform(adult_orig_test_pred.features)\n",
    "y_test = adult_orig_test_pred.labels\n",
    "adult_orig_test_pred.scores = adult_orig_lr.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal parameters from the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold for classification only (no fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy (no fairness constraints) = 0.7500\n",
      "Optimal classification threshold (no fairness constraints) = 0.2377\n"
     ]
    }
   ],
   "source": [
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = adult_orig_validate_pred.scores > class_thresh\n",
    "    adult_orig_validate_pred.labels[fav_inds] = adult_orig_validate_pred.favorable_label\n",
    "    adult_orig_validate_pred.labels[~fav_inds] = adult_orig_validate_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(adult_orig_validate,\n",
    "                                             adult_orig_validate_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no fairness constraints) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no fairness constraints) = %.4f\" % best_class_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr-validate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2. Validating LR model from original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics function\n",
    "from collections import OrderedDict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
    "    \n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7500\n",
      "Statistical parity difference = -0.3842\n",
      "Disparate impact = 0.2590\n",
      "Average odds difference = -0.3279\n",
      "Equal opportunity difference = -0.3746\n",
      "Theil index = 0.1074\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_inds = adult_orig_validate_pred.scores > best_class_thresh\n",
    "adult_orig_validate_pred.labels[fav_inds] = adult_orig_validate_pred.favorable_label\n",
    "adult_orig_validate_pred.labels[~fav_inds] = adult_orig_validate_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_valid_bef = compute_metrics(adult_orig_validate, adult_orig_validate_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr-test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.3. Testing LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7422\n",
      "Statistical parity difference = -0.3908\n",
      "Disparate impact = 0.2689\n",
      "Average odds difference = -0.3386\n",
      "Equal opportunity difference = -0.3780\n",
      "Theil index = 0.1101\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_inds = adult_orig_test_pred.scores > best_class_thresh\n",
    "adult_orig_test_pred.labels[fav_inds] = adult_orig_test_pred.favorable_label\n",
    "adult_orig_test_pred.labels[~fav_inds] = adult_orig_test_pred.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_test_bef = compute_metrics(adult_orig_test, adult_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_orig\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf-train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reweighing-2015\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Bias Mitigation using Post-Processing technique - Reject Option Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to TOC](#toc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reweighing-2015-transform\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. Estimate optimal parameters for the ROC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                  num_class_thresh=100, num_ROC_margin=50,\n",
    "                                  metric_name=metric_name,\n",
    "                                  metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "ROC = ROC.fit(adult_orig_validate, adult_orig_validate_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.5049\n",
      "Optimal ROC margin = 0.1819\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reweighing-2015-metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr_transf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Transforming/Evaluating model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr-rw-validate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2.1. Transforming and Computing Predictions from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.5989\n",
      "Statistical parity difference = -0.0340\n",
      "Disparate impact = 0.6887\n",
      "Average odds difference = -0.0042\n",
      "Equal opportunity difference = -0.0222\n",
      "Theil index = 0.2134\n"
     ]
    }
   ],
   "source": [
    "adult_transf_validate_pred = ROC.predict(adult_orig_validate_pred)\n",
    "\n",
    "display(Markdown(\"#### Validation set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_validate_aft = compute_metrics(adult_orig_validate, adult_transf_validate_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lr-rw-test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3.2. Transforming and Computing Predictions from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6030\n",
      "Statistical parity difference = -0.0436\n",
      "Disparate impact = 0.6164\n",
      "Average odds difference = -0.0162\n",
      "Equal opportunity difference = -0.0337\n",
      "Theil index = 0.2183\n"
     ]
    }
   ],
   "source": [
    "adult_transf_test_pred = ROC.predict(adult_orig_test_pred)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_test_aft = compute_metrics(adult_orig_test, adult_transf_test_pred, \n",
    "                unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deployment-2015-2015\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
